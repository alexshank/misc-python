## 09-27-2025 - Learn Cantrill (AWS Private Link, VPC Endpoints, IPv6, Advanced Network Design)

- AWS Private Link
	- provides private connectivity between VPCs, AWS services, and on-premises applications, securely on the Amazon network
	- primarily used to securely provide a service to another AWS account (or vice versa)
	- remember AZ vs AZ IDs
	- VPC Service Provider and (many) VPC Service Consumers
	- Network Load Balancers (NLBs) and another cross-zone LB ensure HA
		- multiple endpoints also provide HA
	- secured using Security Groups and NACLs
	- secured using typical IAM Users and Roles
	- private DNS is supported
	- works with DX, S2S VPN, and VPC Peering 
	- you just need to know theory for the exam
- VPC Endpoints - Gateway
	- provide private access to public AWS services
	- e.g., access S3 from a private VPC without an IGW or NGW
	- created per service and per region
		- HA by default
		- this is different than VPC Endpoint Interfaces
	- created in a VPC, then assigned to subnets
	- it essentially manages the route table in the VPC subnets to point to the VPC Router, then the AWS services
		- "works using prefix lists and route tables"
		- no changes to your existing applications
	- resource policy (Endpoint Policy) used to control access
	- CANNOT access resources cross-region!!!
		- the VPC Endpoints are NOT accessible outside the VPC
		- even with VPC Peering or Transit Gateways
	- good for preventing leaky S3 buckets, only allow access from the VPC Endpoint Gateway
- VPC Endpoints - Interfaces
	- similar functionality to VPC Endpoint Gateways, BUT KEY ARCHITECTURAL DIFFERENCES
		- provide private access to AWS Public Services
	- key difference is they are NOT highly-available by default
	- they are an ENI added to specific subnets
	- remember one subnet means one Available Zone (AZ)!!!	
	- key difference is they are controlled via Security Groups
		- VPC Endpoint Gateways do NOT use SGs, they use IAM permissions
	- resource policies (Endpoint Policies) supported
	- uses AWS PrivateLink under the hood
	- they create new service endpoint DNS your service could use
		- e.g., vpce-123-xyz.sns.us-east-1.vpce.amazonaws.com
	- by default now, PrivateDNS overrides the default DNS for services!!!
		- so, sns.us-east-1.amazonaws.com will magically go to private DNS endpoint
		- "works by using DNS"
		- you do not need to make application changes, because PrivateDNS is the default
- Advanced VPC DNS and DNS Endpoints
	- in all VPCs and subnets, a DNS address (.2) is reserved
		- called the Route53 Resolver (used by default)
		- gives access to both Public and Associated Private Zones
	- this DNS is only accessible from within the VPC, so difficult for hybrid networking
	- before Route53 Endpoints, the solution was a "DNS Forwarder" EC2 instance in the VPC
	- Route53 Endpoints
		- VPC interfaces (ENI) accessible over VPN or DX
		- "inbound" is considered on-premises into AWS
		- "outbound" is handled with Rules for request forwarding
		- can use DX or VPN connections
		- can handle about 10,000 queries per second per endpoint
		- deployed per region (per VPC)
- IPv6 Capabilities in VPCs
	- private and public IPv4 addresses are NOT compatible
		- requires NAT Gateway to translate public IPv4 address
	- you will NEVER see an EC2 instance's operating system configured with a public IP
		- this is handled by gateway appliances outside of EC2
	- every IPv6 addresses is considered public, so NAT is not used
	- each VPC gets an IPv6 CIDR block
		- can BYOIP or have AWS provision you some
		- very large number, again, IPs are no longer scarce resources
		- can have 256 subnets per VPC
	- routing handled the same, but separate route table entries for IPv4 and IPv6
		- this means IPv4 and IPv6 devices can route to one another
	- you can limit IPv6 inbound traffic with an "Egress Only IGW"
		- this gives you the equivalent functionality of IPv4 private address behind a NAT
		- you would need to change the default IPv6 route to point at the Egress Only IGW instead of the standard IGW
		- you can have multiple gateways in a single VPC
	- very common exam question is how to limit IPv6 ingress traffic!!!
	- you can retroactively add IPv6 addressing to existing VPCs and subnets
		- you then configure services (like EC2) to use IPv6 addressing
- Advanced VPC Structure - How Many AZs for High Availability?
	- adding more AZs does not necessarily increase availability (consider application minimums)
	- Buffer AZ, Nomincal AZs, Nominal Instances -> Optimal Apps per AZ
	- Subnets and Tiers
		- separate subnets = separate tiers
		- no longer necessary to use legacy application tier design for infrastructure
		- one big benefit of using more subnets is NACLs that have EXPLICIT DENY
		- you can keep DBs in a public application subnet and just NOT provision it a public IP
			- SGs also limit DB connections from just your application
		- a primary reason to split subnets is for separate route tables
			- e.g., directing different resources to different gateways / on-premise / etc.
				- NAT Gateway can't be in same subnet as the instances that use it (both need different default routes)
			- general rule is you MUST assume routing is shared by ALL resources within a subnet
				- even specific routing rules aren't bulletproof
		- considerations for subnets and tiers
			- public vs private addressing is irrelevant (security can be handled fine)
			- different routing needs -> multiple subnets
			- a public ALB (in a public subnet) can communicate with private instances (in private subnets)
			- multiply your final number of subnetst by your needed number of AZs
